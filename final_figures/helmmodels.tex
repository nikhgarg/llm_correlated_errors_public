\begin{longtable}{lllr}
\caption{Models analyzed from Helm} \label{tab:helmmodels} \\
\toprule
 & model & company & accuracy \\
\midrule
\endfirsthead
\caption[]{Models analyzed from Helm} \\
\toprule
 & model & company & accuracy \\
\midrule
\endhead
\midrule
\multicolumn{4}{r}{Continued on next page} \\
\midrule
\endfoot
\bottomrule
\endlastfoot
0 & writer/palmyra-x-004 & writer & 0.82 \\
1 & writer/palmyra-x-v3 & writer & 0.78 \\
2 & snowflake/snowflake-arctic-instruct & snowflake & 0.66 \\
3 & qwen/qwen2.5-72b-instruct-turbo & qwen & 0.83 \\
4 & qwen/qwen2-72b-instruct & qwen & 0.83 \\
5 & qwen/qwen1.5-110b-chat & qwen & 0.77 \\
6 & qwen/qwen1.5-72b & qwen & 0.77 \\
7 & qwen/qwen1.5-32b & qwen & 0.74 \\
8 & qwen/qwen2.5-7b-instruct-turbo & qwen & 0.71 \\
9 & qwen/qwen1.5-14b & qwen & 0.67 \\
10 & qwen/qwen1.5-7b & qwen & 0.61 \\
11 & openai/gpt-4o-2024-08-06 & openai & 0.85 \\
12 & openai/gpt-4o-2024-05-13 & openai & 0.85 \\
13 & openai/gpt-4-0613 & openai & 0.84 \\
14 & openai/gpt-4-turbo-2024-04-09 & openai & 0.82 \\
15 & openai/gpt-4-1106-preview & openai & 0.81 \\
16 & openai/gpt-4o-mini-2024-07-18 & openai & 0.76 \\
17 & openai/gpt-3.5-turbo-0613 & openai & 0.68 \\
18 & openai/gpt-3.5-turbo-0125 & openai & 0.66 \\
19 & mistralai/mistral-large-2407 & mistralai & 0.81 \\
20 & mistralai/mixtral-8x22b & mistralai & 0.77 \\
21 & mistralai/mixtral-8x7b-32kseqlen & mistralai & 0.71 \\
22 & mistralai/mistral-small-2402 & mistralai & 0.69 \\
23 & mistralai/mistral-large-2402 & mistralai & 0.67 \\
24 & mistralai/open-mistral-nemo-2407 & mistralai & 0.65 \\
25 & mistralai/mistral-7b-instruct-v0.3 & mistralai & 0.59 \\
26 & mistralai/mistral-7b-v0.1 & mistralai & 0.56 \\
27 & microsoft/phi-3-medium-4k-instruct & microsoft & 0.77 \\
28 & microsoft/phi-3-small-8k-instruct & microsoft & 0.76 \\
29 & microsoft/phi-2 & microsoft & 0.57 \\
30 & meta/llama-3.1-405b-instruct-turbo & meta & 0.85 \\
31 & meta/llama-3.2-90b-vision-instruct-turbo & meta & 0.81 \\
32 & meta/llama-3.1-70b-instruct-turbo & meta & 0.81 \\
33 & meta/llama-3-70b & meta & 0.79 \\
34 & meta/llama-2-70b & meta & 0.69 \\
35 & meta/llama-3-8b & meta & 0.65 \\
36 & meta/llama-2-13b & meta & 0.55 \\
37 & meta/llama-3.2-11b-vision-instruct-turbo & meta & 0.54 \\
38 & meta/llama-3.1-8b-instruct-turbo & meta & 0.54 \\
39 & meta/llama-2-7b & meta & 0.45 \\
40 & google/gemini-1.5-pro-002 & google & 0.86 \\
41 & google/gemini-1.5-pro-001 & google & 0.83 \\
42 & google/gemini-1.5-pro-preview-0409 & google & 0.81 \\
43 & google/text-unicorn@001 & google & 0.78 \\
44 & google/gemini-1.5-flash-001 & google & 0.78 \\
45 & google/gemini-1.5-flash-preview-0514 & google & 0.77 \\
46 & google/gemma-2-27b & google & 0.75 \\
47 & google/gemini-1.5-flash-002 & google & 0.74 \\
48 & google/gemma-2-9b & google & 0.70 \\
49 & google/gemini-1.0-pro-001 & google & 0.70 \\
50 & google/text-bison@001 & google & 0.68 \\
51 & google/gemma-7b & google & 0.65 \\
52 & deepseek-ai/deepseek-llm-67b-chat & deepseek-ai & 0.73 \\
53 & databricks/dbrx-instruct & databricks & 0.73 \\
54 & cohere/command-r-plus & cohere & 0.69 \\
55 & cohere/command-r & cohere & 0.65 \\
56 & anthropic/claude-3-5-sonnet-20241022 & anthropic & 0.88 \\
57 & anthropic/claude-3-5-sonnet-20240620 & anthropic & 0.87 \\
58 & anthropic/claude-3-opus-20240229 & anthropic & 0.85 \\
59 & anthropic/claude-3-sonnet-20240229 & anthropic & 0.76 \\
60 & anthropic/claude-2.1 & anthropic & 0.73 \\
61 & anthropic/claude-3-haiku-20240307 & anthropic & 0.73 \\
62 & anthropic/claude-instant-1.2 & anthropic & 0.68 \\
63 & allenai/olmo-1.7-7b & allenai & 0.53 \\
64 & allenai/olmo-7b & allenai & 0.29 \\
65 & ai21/jamba-1.5-large & ai21 & 0.78 \\
66 & ai21/jamba-1.5-mini & ai21 & 0.69 \\
67 & ai21/jamba-instruct & ai21 & 0.66 \\
68 & 01-ai/yi-large-preview & 01-ai & 0.80 \\
69 & 01-ai/yi-34b & 01-ai & 0.76 \\
70 & 01-ai/yi-6b & 01-ai & 0.63 \\
\end{longtable}
